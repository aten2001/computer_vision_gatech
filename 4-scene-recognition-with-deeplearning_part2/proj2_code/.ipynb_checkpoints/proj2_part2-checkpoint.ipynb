{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "fiK4QNWKDvWJ",
    "outputId": "0e498e6b-9c67-40e3-ff46-837f888d8377"
   },
   "source": [
    "# Scene Recognition with Deep Learning\n",
    "\n",
    "## Brief\n",
    "- Due\n",
    "    - Part 1 Code 09/30/2020 11:59PM (released earlier)\n",
    "    - Part 2 Code 10/13/2020 11:59PM (this notebook)\n",
    "    - Report 10/13/2020 11:59PM (in the zip)\n",
    "- Hand-in: through Gradescope\n",
    "- Required files: \n",
    "    - `<your_gt_username>.zip` against [Project 2 - Part 2 - Code (Individual)](https://www.gradescope.com/courses/155064/assignments/699611) or [Project 2 - Part 2 - Code (Partner)](https://www.gradescope.com/courses/155064/assignments/699616/)\n",
    "    - PDF report against [Project 2 - Report](https://www.gradescope.com/courses/155064/assignments/699620)\n",
    "        \n",
    "### Note:\n",
    "1. Working on pairs and individual submissions have already been decided. You cannot switch now.\n",
    "2. You need to copy-paste your all the .py files from the part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-TUO3hQhZ-2"
   },
   "source": [
    "## Outline\n",
    "In this project, we will use *convolutional neural nets* to classify images into different scenes.\n",
    "\n",
    "Basic learning objectives of this project:\n",
    "1. Construct the fundamental pipeline for performing deep learning using PyTorch;\n",
    "2. Understand the concepts behind different layers, optimizers.\n",
    "3. Experiment with different models and observe the performance.\n",
    "\n",
    "The starter code is mostly initialized to 'placeholder' just so that the starter\n",
    "code does not crash when run unmodified and you can get a preview of how\n",
    "results are presented.\n",
    "\n",
    "## Compute Requirements\n",
    "\n",
    "This project is doable without a GPU, but a GPU makes the process much more faster and frustration free.\n",
    "\n",
    "You can try out Google Colab to run this notebook. These are the steps we follow:\n",
    "1. Upload this notebook to google colab\n",
    "2. Zip all the components in the project directory and upload it to the colab runtime\n",
    "3. Unzip the uploaded zip using ```!unzip -qq <uploaded_file>.zip -d ./```\n",
    "\n",
    "Remember to download all the files saved and changes to code you made on the colab.\n",
    "\n",
    "Note that we will not be actively supporting issues with Google colab. Please take help from fellow students and use the internet to solve the issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3KVmDW-TdjI"
   },
   "source": [
    "## Dataset\n",
    "The dataset is in the ```data``` folder. It has two subfolders: ```train``` and ```test```. Go through any of the folder and find there you will find the folders with scene names like *bedroom*, *forest*, *office*. These are the 15 scenes that we want our model to predict given an RGB image. You can look into folder for each scene to find multiple images. All this data is labelled data provided to you for training and testing your model.\n",
    "\n",
    "**Let's start coding now!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFVeSYKzTdjK"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QRsVzCGTdjB"
   },
   "outputs": [],
   "source": [
    "# uncomment for running on colab\n",
    "# !unzip -qq proj2_colab.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kTYp67dhZ_D"
   },
   "outputs": [],
   "source": [
    "# flag to modify paths to run better on Colab; change it to true if you want to run on colab\n",
    "use_colab_paths = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA7pA3FWhZ_I"
   },
   "source": [
    "## Dataset\n",
    "The dataset is in the ```data``` folder. It has two subfolders: ```train``` and ```test```. Go through any of the folder and find there you will find the folders with scene names like *bedroom*, *forest*, *office*. These are the 15 scenes that we want our model to predict given an RGB image. You can look into folder for each scene to find multiple images. All this data is labelled data provided to you for training and testing your model.\n",
    "\n",
    "**Let's start coding now!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DikW12-RhZ_J"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1dqr6qSBpE2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from proj2_code.runner import Trainer\n",
    "from proj2_code.optimizer import get_optimizer\n",
    "from proj2_code.simple_net import SimpleNet\n",
    "from proj2_code.simple_net_dropout import SimpleNetDropout\n",
    "from proj2_code.my_alexnet import MyAlexNet\n",
    "from proj2_code.image_loader import ImageLoader\n",
    "from proj2_code.data_transforms import get_fundamental_transforms, get_data_augmentation_transforms\n",
    "from proj2_code.stats_helper import compute_mean_and_std\n",
    "from proj2_code.vis import visualize\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CG3e0869TdjS"
   },
   "outputs": [],
   "source": [
    "from proj2_code.proj2_unit_tests.test_base import verify\n",
    "from proj2_code.proj2_unit_tests.test_stats_helper import test_mean_and_variance\n",
    "from proj2_code.proj2_unit_tests.test_image_loader import test_dataset_length, test_unique_vals, test_class_values, test_load_img_from_path\n",
    "from proj2_code.proj2_unit_tests.test_data_transforms import test_fundamental_transforms\n",
    "from proj2_code.proj2_unit_tests.test_dl_utils import test_predict_labels, test_compute_loss\n",
    "from proj2_code.proj2_unit_tests.test_simple_net import test_simple_net\n",
    "from proj2_code.proj2_unit_tests.test_simple_net_dropout import test_simple_net_dropout\n",
    "from proj2_code.proj2_unit_tests.test_my_alexnet import test_my_alexnet\n",
    "from proj2_code.proj2_unit_tests.test_checkpoints import test_simple_net_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjE0jIc5BpFN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "is_cuda = True\n",
    "is_cuda = is_cuda and torch.cuda.is_available() # will turn off cuda if the machine doesnt have a GPU\n",
    "\n",
    "print(is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKRS4gvZTdji"
   },
   "outputs": [],
   "source": [
    "data_base_path = '../data/' if not use_colab_paths else 'data/'\n",
    "model_base_path = '../model_checkpoints/' if not use_colab_paths else 'model_checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1QoVOsGwhZ_j",
    "outputId": "433432c2-bfe7-4d68-93bd-4579415578cf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n",
      "['alexnet', 'simple_net_dropout', 'simple_net_ablation', 'quantized_alexnet', 'simple_net']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(data_base_path))\n",
    "print(os.listdir(model_base_path))\n",
    "\n",
    "# TODO: check that these outputs are as per expectation. It will save a lot of time in debugging issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nulEn5fzTdjs"
   },
   "source": [
    "To train a network in PyTorch, we need 4 components:\n",
    "1. **Dataset** - an object which can load the data and labels given an index.\n",
    "2. **Model** - an object that contains the network architecture definition.\n",
    "3. **Loss function** - a function that measures how far the network output is from the ground truth label.\n",
    "4. **Optimizer** - an object that optimizes the network parameters to reduce the loss value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B027mwlKTdjt"
   },
   "source": [
    "## 1 Datasets\n",
    "One crucial aspect of deep learning is to perform data preprocessing. In DL, we usually *normalize* the dataset and perform some *transformations* on them. The transformations can either help the inputs be compatible with the model (say our model only works on 500x500 images and we need all input to be cropped/scaled to this size) or help in data-augmentation to improve performance (more on this later).\n",
    "\n",
    "\n",
    "### 1.1 Compute mean and standard deviation of the dataset\n",
    "In this project we are going to \"zero-center\" and \"normalize\" the dataset so that each entry has zero mean and the overall standard deviation is 1. \n",
    "\n",
    "**TODO 1**:  fill in the `compute_mean_and_std()` in `stats_helper.py` to compute the **mean** and **standard deviation** of both training and validation data.\n",
    "\n",
    "Debug tip: If you face an error from StandardScaler about attribute not found, please check that the paths are correct and your code actually finds some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vWA_2UbjBpFd",
    "outputId": "c84201a5-d7c9-4e0e-9b42-5fb784034556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your mean and std computation:  \u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing your mean and std computation: \", verify(test_mean_and_variance))\n",
    "dataset_mean, dataset_std = compute_mean_and_std(data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xixFr8CDBpFn",
    "outputId": "e5da02f4-ac00-4443-8144-4e4e72bb1555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mean = [0.45547487], standard deviation = [0.25316328]\n"
     ]
    }
   ],
   "source": [
    "print('Dataset mean = {}, standard deviation = {}'.format(dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2TeGbrQBpFu"
   },
   "source": [
    "### 1.2 ImageLoader\n",
    "\n",
    "Now let's create the **Datasets** object to be used later. Remember back in Project 1, we have initialized such a class to load 5 images? Here the task is similar: we have to load each image as well as it's classification label. The essence is to retrieve the paths to all the images required, and be able to provide the **path** and the **class id** when given an index.\n",
    "\n",
    "We will map the scene names (text) into indices 0 to 14 in the image loader. You can choose any mapping you want but once fixed, it has to be consistent throughout this notebook.\n",
    "\n",
    "**TODO 2:** complete the `image_loader.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "THRvAvluXFcS",
    "outputId": "e66e0cdf-a832-4504-bb31-08e4eda96145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your image loader (length): \u001b[32m\"Correct\"\u001b[0m\n",
      "Testing your image loader (values): \u001b[32m\"Correct\"\u001b[0m\n",
      "Testing your image loader (classes): \u001b[32m\"Correct\"\u001b[0m\n",
      "Testing your image loader (paths): \u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "inp_size = (64,64)\n",
    "print(\"Testing your image loader (length):\", verify(test_dataset_length))\n",
    "print(\"Testing your image loader (values):\", verify(test_unique_vals))\n",
    "print(\"Testing your image loader (classes):\", verify(test_class_values))\n",
    "print(\"Testing your image loader (paths):\", verify(test_load_img_from_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIq75D2CTdkC"
   },
   "source": [
    "### 1.3 Data transforms\n",
    "In this section, we will construct some fundamental transforms to process RGB images into torch tensors, which we can provide as input to our model.\n",
    "\n",
    "1. Resize the input image to the desired shape;\n",
    "2. Convert it to a tensor;\n",
    "3. Normalize them based on the computed mean and standard deviation.\n",
    "\n",
    "**TODO 3:** For this part, complete the function `get_fundamental_transforms()` in `data_transforms.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZoAaL11nTdkD",
    "outputId": "e95d0343-9107-462b-aebe-2f6990efdd08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your fundamental data transforms:  \u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing your fundamental data transforms: \", verify(test_fundamental_transforms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sWOnZmNTdkJ"
   },
   "source": [
    "## 2 Model Architecture and Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bg59TFXHTdkL"
   },
   "source": [
    "### 2.1 SimpleNet Model\n",
    "\n",
    "The data is ready! Now we are preparing to move to the actual core of deep learning: the architecture. To get you started in this part, simply define a **2-layer** model in the `simple_net.py`. Here by \"2 layers\" we mean **2 convolutional layers**, so you need to figure out the supporting utilities like ReLU, Max Pooling, and Fully Connected layers, and configure them with proper parameters to make the tensor flow.\n",
    "\n",
    "You may refer the image *simplenet.jpg* in the base folder for a sample network architecture (it's the architecture TAs used in their implementation and is sufficient to get you pass Part 1).\n",
    "\n",
    "**TODO 4**: Do the following in ```simple_net.py```:\n",
    "- Initialize ```self.cnn_layers```\n",
    "- Initialize ```self.fc_layers```\n",
    "- Write the forward function\n",
    "\n",
    "Leave the ```self.loss_criterion = None``` for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jvVL-ap0BpFx",
    "outputId": "d97819e7-741e-4d37-82ea-8351dd103dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your SimpleNet architecture:  \u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing your SimpleNet architecture: \", verify(test_simple_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_YLUulTTdkX"
   },
   "source": [
    "### 2.2 Output prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNBpN4ofTdkZ"
   },
   "source": [
    "Let's see what out model's forward function produces for a sample input, and how it relates to classification. Pytorch's convolution and FC layers are initialized with random weights. So we should not expect any useful output without any training.\n",
    "\n",
    "We will use a data-point from the dataloader we have already created and run the model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IW3f_SgTdkc"
   },
   "outputs": [],
   "source": [
    "simple_model = SimpleNet()\n",
    "\n",
    "image_loader = ImageLoader(data_base_path, \n",
    "                           split='train', \n",
    "                           transform=get_fundamental_transforms(inp_size, dataset_mean, dataset_std)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyQDxArjTdkg"
   },
   "outputs": [],
   "source": [
    "# get the 0th sample\n",
    "sample_image, sample_label = next(iter(image_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "myJ9kcqUTdkm",
    "outputId": "ec53cd08-979d-41d7-bc7b-07eca46ed064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape =  torch.Size([1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print('Input image shape = ', sample_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "bvHtwSATTdkr",
    "outputId": "ea02c24c-e16c-4af7-e3d1-5b8dc25cf280"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show the image\n",
    "fig, axs = plt.subplots()\n",
    "axs.imshow(sample_image.squeeze().numpy(), cmap='gray')\n",
    "axs.axis('off')\n",
    "axs.set_title('Sample image (Target label = {})'.format(sample_label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0XEqQaNTdkw"
   },
   "outputs": [],
   "source": [
    "# run the image through the model\n",
    "sample_model_output = simple_model(sample_image.unsqueeze(0)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "2v9WUSlbTdkz",
    "outputId": "965375e6-08dd-48da-c4cf-ce3ccef31e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1050,  0.6913,  0.0200, -0.2595,  0.1707, -0.0853,  0.0459, -0.1156,\n",
      "          0.1321, -0.1209, -0.0908, -0.1637,  0.1933,  0.3280, -0.1780]])\n"
     ]
    }
   ],
   "source": [
    "print(sample_model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCtiLVKKTdk3"
   },
   "source": [
    "We have a 15-dimensional tensor as output, but how does it relate to classification?\n",
    "\n",
    "We first convert the this tensor into a probability distribution over 15 classes by applying the [Softmax](https://en.wikipedia.org/wiki/Softmax_function) operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Ssu7W4jTdk4"
   },
   "outputs": [],
   "source": [
    "sample_probability_values = torch.nn.functional.softmax(sample_model_output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4BXWrwl0Tdk9",
    "outputId": "eb041618-7ba1-4ded-ce43-5eb8a395ac86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0564, 0.1251, 0.0639, 0.0483, 0.0743, 0.0575, 0.0656, 0.0558, 0.0715,\n",
      "         0.0555, 0.0572, 0.0532, 0.0760, 0.0870, 0.0524]])\n"
     ]
    }
   ],
   "source": [
    "print(sample_probability_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTABRuGpTdlD"
   },
   "source": [
    "The prediction of the model will be the index where the probability distribution is the maximum. Convince yourself that the argmax-operation on *sample_model_values* is the same as the argmax-operation on *sample_probability_values*.\n",
    "\n",
    "**TODO 5:** Complete the ```predict_labels()``` function in ```dl_utils.py```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w3j6LNUyTdlD"
   },
   "source": [
    "## 3 Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2mIs5sQTdlE"
   },
   "source": [
    "We have written a model which takes in a tensor for an image and produces a 15 dimensional output for it. We saw in the previous section on how the output relates to the prediction and probability distribution. But how do we quantify the performance of the model, and how do we use that quantification to form an objective function which we can minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1esn_cCXTdlE"
   },
   "source": [
    "Ideally, we would want the probability function to have value 1 for the target *sample_label* and value 0 for the remaining class indices. To penalize the deviation between the desired probability distribution and the model-predicted distrtibution, we use the KL-divergence loss or the cross-entropy loss. Please refer to [this stackexchange post](https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation) for a good explanation and derivation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvSEgfOBTdlF"
   },
   "source": [
    "**TODO 6:** Assign a loss function to ```self.loss_criterion``` in ```simple_net.py```. Note that we have not done a softmax operation in the model's forward function and choose the [appropriate loss function](https://pytorch.org/docs/stable/nn.html#loss-functions).\n",
    "\n",
    "**TODO 7:** Complete the ```compute_loss()``` function in ```dl_utils.py``` to use the model's loss criterion and compute the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9Y3TEv7TdlG"
   },
   "outputs": [],
   "source": [
    "simple_model = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "Y2Lu0S_ETdlK",
    "outputId": "584fd9e2-1fbf-47c7-dc18-81e70ebfc2c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten()\n",
      "    (1): Linear(in_features=500, out_features=200, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=200, out_features=15, bias=True)\n",
      "  )\n",
      "  (loss_criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(simple_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hbcEPDN0TdmF",
    "outputId": "4545c9ed-1dcb-45fe-eaba-c51d21163bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your model prediction:  \u001b[32m\"Correct\"\u001b[0m\n",
      "Testing your loss values:  \u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing your model prediction: \", verify(test_predict_labels))\n",
    "print(\"Testing your loss values: \", verify(test_compute_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKQCj596TdlQ"
   },
   "source": [
    "## 4 Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CB0oPQtVTdlR"
   },
   "source": [
    "### 4.1 Manual gradient descent using Pytorch's autograd\n",
    "\n",
    "Till now, we have defined the model, and designed a loss function which is a proxy for *good* classification. We now to optimize the weights of the network so that the loss function is minimized.\n",
    "\n",
    "Pytorch is a very useful library for deep learning because a lot of tensor operations and functions support the flow of gradients. This feature is called [autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html). This functionality lets use use gradient based optimization techniques like gradient descent without writing a lot of code.\n",
    "\n",
    "Let us first understand how we can access the gradients.\n",
    "\n",
    "### Define a model and a loss function\n",
    "Suppose we have a simple objective function that looks like:\n",
    "$$ L(w) =  w^2 - 10w + 25 $$\n",
    "\n",
    "This is a convex problem, and we know that the loss $L$ is minimized for $w=5$, and we can obtain this in closed form.\n",
    "\n",
    "But let us use gradient descent to obtain the solution in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLu-7PG1TdlS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "def quadratic_loss(w: tensor) -> tensor:\n",
    "    assert w.shape==(1,)\n",
    "\n",
    "    # loss function\n",
    "    L = torch.pow(w, 2) - 10 * w + 25\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPVWOjo6TdlW"
   },
   "source": [
    "Let's compute the loss at w = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pbVokXpUTdlX",
    "outputId": "666d20f0-39b9-4719-fe4c-338e2e117534"
   },
   "outputs": [],
   "source": [
    "w = tensor([0.0], requires_grad=True)\n",
    "\n",
    "loss = quadratic_loss(w)\n",
    "\n",
    "print('w={:.4f}\\tLoss={:.4f}'.format(w.detach().numpy().item(), loss.detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AabZ-6MnTdla"
   },
   "source": [
    "Now we can do a backward pass of the gradients to get the gradient of loss w.r.t w. Now we need to calculate the gradients with regard to the weights and biases using backprop. It will be very painful if we do it manually, but thankfully, in PyTorch we can have everything covered with autograd, which only needs a simple call of **.backward()** on our loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jcrIh9P3Tdlb",
    "outputId": "2f5b1efe-ece3-433e-e583-3f3e204f3adf"
   },
   "outputs": [],
   "source": [
    "# perform backward on loss (we need to retain graph here otherwise Pytorch will throw it away)\n",
    "loss.backward(retain_graph=True)\n",
    "\n",
    "print(w.grad.data)\n",
    "\n",
    "# manually zero out the gradient\n",
    "w.grad.zero_()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAPF2cBATdlf"
   },
   "source": [
    "Does this gradient match with the one you compute manually?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmd3JnxzTdli"
   },
   "source": [
    "With the gradients, we can update the weights and biases using gradient descent:\n",
    "$$w_{k+1}=w_{k} - \\alpha\\frac{\\partial L}{\\partial w_k}$$\n",
    "where $w$ is the parameter we are updating, $\\alpha$ is the learning rate, and $\\frac{\\partial L}{\\partial w_k}$ is the gradient at step $k$. You can learn more about gradient descent [here](https://en.wikipedia.org/wiki/Gradient_descent) and [here](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIhMyeflTdlj"
   },
   "outputs": [],
   "source": [
    "# set learning rate\n",
    "lr = .03\n",
    "\n",
    "def gradientDescentStep(w: tensor, L: tensor, lr: float=1e-3) -> None:\n",
    "    '''\n",
    "    Take a step of the gradient descent\n",
    "    '''\n",
    "    \n",
    "    # manually zero out the gradient\n",
    "    w.grad.zero_()\n",
    "\n",
    "    # perform backward on loss (we need to retain graph here otherwise Pytorch will throw it away)\n",
    "    L.backward(retain_graph=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMEZ9eHuTdlm"
   },
   "source": [
    "Let's take one step of the gradient descent and check if the the loss value decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BuBQHZwTdln"
   },
   "outputs": [],
   "source": [
    "loss = quadratic_loss(w)\n",
    "\n",
    "gradientDescentStep(w, loss, lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yIWP3Tv4Tdlq",
    "outputId": "ba32ccb8-73d9-4a1d-ab6f-4822df3eb4eb"
   },
   "outputs": [],
   "source": [
    "loss = quadratic_loss(w)\n",
    "print('w={:.4f}\\tLoss={:.4f}'.format(w.detach().numpy().item(), loss.detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Mb4IdocTdlv"
   },
   "source": [
    "Looks like it's been optimized!\n",
    "\n",
    "Now let's run a few more updates and see where we can get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "FTfmRlc0Tdlv",
    "outputId": "0b111b50-90d6-47a2-b870-c05c2fc1b88a"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(200):\n",
    "    loss = quadratic_loss(w)\n",
    "    if not (i+1)%10:\n",
    "        print('Iteration {}: w={:.4f}\\tLoss={:.4f}'.format(\n",
    "            i+1, w.detach().numpy().item(), loss.detach().numpy().item()))\n",
    "        \n",
    "    gradientDescentStep(w, loss, lr) \n",
    "        \n",
    "print('\\noptimization takes %0.3f seconds'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTFEo_JMTdlz"
   },
   "source": [
    "Seems that it's doing a great job training our model! The loss now has decreased significantly to a pretty small value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMtBy2JvTdl0"
   },
   "source": [
    "### 4.2 Optimization using Pytorch's gradient descent optimizer\n",
    "\n",
    "Now let's see how we can simplify this using the `torch.optim` package from PyTorch. You can see that using optimizer from `torch.optim` package can achieve the same results with a lot less code from our side. Also, there are many features available over the vanilla gradient descent. Let's use the Stochastic Gradient Descent (SGD) optimizer available in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "YKb3ngxtTdl1",
    "outputId": "b444730f-5b89-4ecb-c5c5-95a93833d851"
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "# define parameters we want to optimize\n",
    "w = tensor([0.0], requires_grad=True)\n",
    "\n",
    "optimizer = SGD([w], lr=lr)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(200):\n",
    "    loss = quadratic_loss(w)   \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if not (i+1)%10:\n",
    "        print('Iteration {}: w={:.4f}\\tLoss={:.4f}'.format(\n",
    "            i+1, w.detach().numpy().item(), loss.detach().numpy().item()))\n",
    "        \n",
    "print('\\noptimization takes %0.3f seconds'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4IsnddUCTdl5"
   },
   "source": [
    "### 4.3 Setting up the optimizer for SimpleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OxeVYy1bTdl6"
   },
   "source": [
    "**TODO 8:** **initialize the following cell with proper values for learning rate and weight decay** \n",
    "\n",
    "**Note:** There is nothing to do in this TODO for the first pass. You'll train the model with these values and it will be bad. Then you can come back here and tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2cwtK5PBpF7"
   },
   "outputs": [],
   "source": [
    "# TODO: add a decent initial setting and tune from there\n",
    "optimizer_config = {\n",
    "  \"optimizer_type\": \"AdamW\",\n",
    "  \"lr\": 1e-4,\n",
    "  \"weight_decay\": 1e-2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3pyzj8KTdl_"
   },
   "source": [
    "We will now set up a utility function to define an optimizer on the loss for a model.\n",
    "\n",
    "**TODO 9:** complete the ```get_optimizer()``` function in ```optimizer.py```. The helper function accepts three basic configurations as defined below. Any other configuration is optional. *SGD* optimizer type should be supported, anything else is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0CrYZa4BpGE"
   },
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(simple_model, optimizer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3b8cjmrSTdmK"
   },
   "source": [
    "## 5 Training SimpleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBrJnj2tTdmL"
   },
   "source": [
    "We have completed all the components required to train the first model for this course. Let's pass in the model architecture, optimizer, transforms for both the training and testing datasets into the trainer, and proceed to the next cell to train it. If you have implemented everything correctly, you should be seeing a decreasing loss value.\n",
    "\n",
    "**Note** in this project, we will be using the test set as the validation set (i.e. using it to guide our decisions about models and hyperparamters while training. In actual practise, you would not interact with the test set until reporting the final results.\n",
    "\n",
    "**Note** that your CPU should be sufficient to handle the training process for all networks in this project, and the following training cells will take less than 5 minutes; you may also want to decrease the value for `num_epochs` and quickly experiment with your parameters. The default value of **30** is good enough to get you around the threshold for Part 1, and you are free to increase it a bit and adjust other parameters in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiGOvPJfBpGO"
   },
   "outputs": [],
   "source": [
    "# re-init the model so that the weights are all random\n",
    "simple_model = SimpleNet()\n",
    "optimizer = get_optimizer(simple_model, optimizer_config)\n",
    "\n",
    "trainer = Trainer(data_dir=data_base_path, \n",
    "                  model = simple_model,\n",
    "                  optimizer = optimizer,\n",
    "                  model_dir = os.path.join(model_base_path, 'simple_net'),\n",
    "                  train_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = False,\n",
    "                  cuda = is_cuda\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "paNLyU5cBpGX",
    "outputId": "e8506469-b4e5-4aa6-9423-8235b96068ab"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "simple_net_start = time.time()\n",
    "trainer.train(num_epochs=30)\n",
    "simple_net_end = time.time()\n",
    "print(\"The training time taken for simple net is {:.9f}\".format(simple_net_end-simple_net_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jv1T8xv2TdmR"
   },
   "source": [
    "Now let's have your model predict on some examples and see how well it performs qualitatively. You should try the following cell multiple times to understand whats happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "thCGob3JTdmR",
    "outputId": "1629bc1c-8972-46ce-8cdb-0b420c0337cb"
   },
   "outputs": [],
   "source": [
    "# visualize train split\n",
    "print(\"Examples from train split:\")\n",
    "visualize(simple_model, 'train', get_fundamental_transforms(inp_size, dataset_mean, dataset_std), data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "QQbkZhjlTdmU",
    "outputId": "d227b903-2c31-4a5e-b3b2-8ade627c0791"
   },
   "outputs": [],
   "source": [
    "# visualize test split\n",
    "print(\"Examples from test split:\")\n",
    "visualize(simple_model, 'test', get_fundamental_transforms(inp_size, dataset_mean, dataset_std), data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "z0b_WwJhBpGf",
    "outputId": "3d80145a-dd14-40fd-f30c-9f47ac0f4d75",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.plot_loss_history()\n",
    "trainer.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8epn0IBmBpGn",
    "outputId": "23555727-ed23-490d-ddfc-783fa439101d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_accuracy = trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = trainer.validation_accuracy_history[-1]\n",
    "print('Train Accuracy = {:.4f}; Validation Accuracy = {:.4f}'.format(train_accuracy, validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CQKKbNc2haCZ",
    "outputId": "8ef542c8-409c-4ed2-840f-198a711e66e1"
   },
   "outputs": [],
   "source": [
    "print('Testing simple net weights saved: ', verify(test_simple_net_checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWNCMmRzTdmc"
   },
   "source": [
    "After you have finished the training process, now plot out the loss and accuracy history. You can also check out the final accuracy for both training and validation data. Copy the accuracy plots and values onto the report, and answer the questions there. \n",
    "\n",
    "**TODO 10:** Obtain a **45%** validation accuracy to receive full credits for Part 1. You can go back to TODO 8 first to tune your paramters for optimization using the following tips:\n",
    "\n",
    "**Tips**:\n",
    "1. If the loss decreases very slowly, try increasing the value of the lr (learning rate).\n",
    "2. Initially keep the value of weight decay (L2-regulization) very low.\n",
    "3. Try to first adjust lr in multiples of 3 initially. When you are close to reasonable performance, do a more granular adjustment.\n",
    "4. If you want to increase the validation accuracy by a little bit, try increasing the weight_decay to prevent overfitting. Do not use tricks from Section 6 just yet.\n",
    "\n",
    "If you still need to tweak the model architecture, you are free to do so. But remember complex models will require more time to train, and TAs could achieve ~50% accuracy with the described model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7hE1vidBpGt"
   },
   "source": [
    "## 6 Solving overfitting\n",
    "We have obtained a 45% accuracy on the validation data with a simple model; Feeling even better for the training accuracy right? More than 90% (if you have implemented everything correctly). But should you?\n",
    "\n",
    "Our final accuracies for training and validation data differ a lot from each other, which indicates that the model we have defined **fits too well with the training data, but is unable to generalize well on data it has not trained on**: this is often regarded as **overfitting**. In this section we are going to apply 2 techniques to tackle with it: adjusting both data and model.\n",
    "\n",
    "### 6.1 Jitter, Random Flip, and Normalization\n",
    "One common technique to increase the \"variability\" of the data is to **augment** it. Firstly, we don't have a huge amount of data, so let's \"jitter\" it; secondly, when you mirror an image of a **kitchen**, you can tell that the mirrored image is still a kitchen. \n",
    "\n",
    "**TODO 11:** finish the `get_data_augmentation_transforms()` function in `data_transforms.py`: you should first copy your existing fundamental transform implementation into this function, and then insert a couple of other transforms which help you do the above adjustment\n",
    "\n",
    "You are free to experiment with different kinds of augmentation techniques by adding new techniques or replacing existing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ech4Y22OXOui"
   },
   "outputs": [],
   "source": [
    "inp_size = (64,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06cXE2wkTdmg"
   },
   "source": [
    "### 6.2 Dropout\n",
    "\"Dropout\" is a technique commonly used to regularize the network. It randomly turns off the connection between neurons inside the network and prevent the network from relying too much on a specific neuron. \n",
    "\n",
    "**TODO 12:** finish the `simple_net_dropout.py` with your previous SimpleNet model, plus the dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "adEPCL3QTdmi",
    "outputId": "370d27dc-8c72-4f4f-af1f-172c0a68cd15"
   },
   "outputs": [],
   "source": [
    "print(\"Testing your SimpleNetDropout architecture: \", verify(test_simple_net_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "nlgm5eM-BpGz",
    "outputId": "d0cf7323-6648-4c3c-9410-09d04e76c40a"
   },
   "outputs": [],
   "source": [
    "simple_model_dropout = SimpleNetDropout()\n",
    "print(simple_model_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmmpMDRBTdmm"
   },
   "source": [
    "Similar to the previous part, **initialize the following cell with proper values for learning rate and weight decay**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btKIvIrdBpG5"
   },
   "outputs": [],
   "source": [
    "# TODO: add a decent initial setting and tune from there\n",
    "optimizer_config = {\n",
    "  \"optimizer_type\": \"AdamW\",\n",
    "  \"lr\": 1e-4,\n",
    "  \"weight_decay\": 1e-3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExoLylurBpHH"
   },
   "outputs": [],
   "source": [
    "simple_model_dropout = SimpleNetDropout()\n",
    "optimizer = get_optimizer(simple_model_dropout, optimizer_config)\n",
    "\n",
    "trainer = Trainer(data_dir=data_base_path, \n",
    "                  model = simple_model_dropout,\n",
    "                  optimizer = optimizer,\n",
    "                  model_dir = os.path.join(model_base_path, 'simple_net_dropout'),\n",
    "                  train_data_transforms = get_data_augmentation_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = False,\n",
    "                  cuda = is_cuda\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zq2__3ZQTdmt"
   },
   "source": [
    "The following cell will take longer than Part 1, as now we have more data (and more variability), and the model is slightly more complicated than before as well; however, it should finish within 10~15 minutes anyway, and the default `num_epochs` is also good enough as a starting point for you to pass this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "-ljUl4UnBpHN",
    "outputId": "8f6c2e23-917b-483e-a4c5-01015a84d480",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3yOROVGTdmy"
   },
   "source": [
    "Now let's have your model predict on some examples and see how well it performs qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "732LGRJCftzL"
   },
   "outputs": [],
   "source": [
    "# # visualize train split\n",
    "print(\"Examples from train split:\")\n",
    "visualize(simple_model_dropout, 'train', get_fundamental_transforms(inp_size, dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jum7rI93Tdm0"
   },
   "outputs": [],
   "source": [
    "# # visualize test split\n",
    "print(\"Examples from test split:\")\n",
    "visualize(simple_model_dropout, 'test', get_fundamental_transforms(inp_size, dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "Gdh9AvHIBpHW",
    "outputId": "95f03c53-13c8-41b3-bb40-0da8262cb685",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.plot_loss_history()\n",
    "trainer.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6SLuc3zmBpHd",
    "outputId": "095b6b08-2d99-4d85-a1f9-4273bd1546b7"
   },
   "outputs": [],
   "source": [
    "train_accuracy = trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = trainer.validation_accuracy_history[-1]\n",
    "print('Train Accuracy = {:.4f}; Validation Accuracy = {:.4f}'.format(train_accuracy, validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBLf3n6aTdnJ"
   },
   "source": [
    "Similar to the previous part, now plot out the loss and accuracy history. Also copy the plots onto the report, and answer the questions accordingly.\n",
    "\n",
    "**TODO 13:** Achieve **52%** validation accuracy for full credits for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amh1wxlJBpHj"
   },
   "source": [
    "## 7 Pretrained AlexNet\n",
    "You can see that after the above adjustment, our model performance increases in terms of testing accuracy. Although the training accuracy drops, now it's closer to the testing values and that's more natural in terms of performance. But we are not satisfied with the final performance yet. Our model, in the end, is still a 2-layer SimpleNet and it might be capable of capturing some features, but could be improved a lot if we go **deeper**. In this part we are going to see the power of a famous model: AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttbhBZ7CXUng"
   },
   "outputs": [],
   "source": [
    "inp_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BMfz9HrpTdnO"
   },
   "source": [
    "PyTorch has provided us with pre-trained models like AlexNet, so what you want to do is to load the model first, and then adjust some of the layers such that it fits with our own dataset, instead of outputing scores to 1000 classes from the original AlexNet model.\n",
    "\n",
    "There are many reasons for using pre-trained weights instead of training AlexNet from scratch:\n",
    "1. We have a really small dataset. Alexnet has millions of parameters and will definitely overfit. The pre-trained alexnet will have access to millions of training images.\n",
    "2. We save a lot of computation.\n",
    "\n",
    "**TODO 14:** Switch to `my_alexnet.py`, and copy the network architecture and weights of all but the last fc layers from the pretrained network.\n",
    "\n",
    "After you have defined the correct architecture of the model, make some tweaks to the existing layers: **freeze** the **convolutional** layers and first 2 **linear** layers so we don't update the weights of them. More instructions are in the docstring.\n",
    "\n",
    "Note that you are allowed to add more layers/unfreeze more layers if you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "0b81f9c1f6bc454a87fe4778bf952649",
      "fd2dd89a02c845749277122b6b6ff950",
      "069982490a6f40c99dd18422032d2c88",
      "5cb5fa8ce08046aab383a70a67501a4b",
      "d6ecbfe7ee7b4d4da398c5ee56badae9",
      "92f6efa8b5fd49e69bdada865cbc3fab",
      "c6638c5846de4196a0a8238b10db6cdd",
      "88ea6259ff60465884b7d21ee6b48479"
     ]
    },
    "colab_type": "code",
    "id": "DmXFp9NdTdnO",
    "outputId": "3fe93ff7-235f-4f24-92d9-652824ba6089"
   },
   "outputs": [],
   "source": [
    "print(\"Testing your AlexNet architecture: \", verify(test_my_alexnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "CBoLgRrlBpHl",
    "outputId": "03113d70-bde0-4e97-9530-bd3cd8123096"
   },
   "outputs": [],
   "source": [
    "my_alexnet = MyAlexNet()\n",
    "print(my_alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6AYkHAgBpHw"
   },
   "outputs": [],
   "source": [
    "# TODO: add a decent initial setting and tune from there\n",
    "optimizer_config = {\n",
    "  \"optimizer_type\": \"SGD\",\n",
    "  \"lr\": 1e-3,\n",
    "  \"weight_decay\": 1e-3,\n",
    "  \"momentum\": 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtCIaTMmBpIK"
   },
   "outputs": [],
   "source": [
    "my_alexnet = MyAlexNet()\n",
    "optimizer = get_optimizer(my_alexnet, optimizer_config)\n",
    "\n",
    "trainer = Trainer(data_dir=data_base_path, \n",
    "                  model = my_alexnet,\n",
    "                  optimizer = optimizer,\n",
    "                  model_dir = os.path.join(model_base_path, 'alexnet'),\n",
    "                  train_data_transforms = get_data_augmentation_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = False,\n",
    "                  cuda = is_cuda\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOeaVrlZTdnY"
   },
   "source": [
    "The following training cell will take roughly 20 minutes or slightly more using CPU (but possibly under 5 minute using GPU depending on the batch size; the TAs got it within 3 minutes on a GTX1060)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "CAcncwLPBpIQ",
    "outputId": "2c47c01f-ab88-4414-bb0e-cb0ef17ac5fa"
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ax5cpYmZTdna"
   },
   "source": [
    "Now let's have your model predict on some examples and see how well it performs qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rc_IeNR9Tdnb"
   },
   "outputs": [],
   "source": [
    "# # visualize train split\n",
    "print(\"Examples from train split:\")\n",
    "visualize(my_alexnet, 'train', get_fundamental_transforms(inp_size, dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMxmCz4WTdnc"
   },
   "outputs": [],
   "source": [
    "# # visualize test split\n",
    "print(\"Examples from test split:\")\n",
    "visualize(my_alexnet, 'test', get_fundamental_transforms(inp_size, dataset_mean, dataset_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "Cimj95G_BpIU",
    "outputId": "d3a0ae4b-6c7c-4b02-cd45-904edd6f45af",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.plot_loss_history()\n",
    "trainer.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qMI3CdEuBpIb",
    "outputId": "ee50a93a-ddad-4114-ed56-eff8f1b16085"
   },
   "outputs": [],
   "source": [
    "train_accuracy = trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = trainer.validation_accuracy_history[-1]\n",
    "print('Train Accuracy = {:.4f}; Validation Accuracy = {:.4f}'.format(train_accuracy, validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T6DN_wGXTdni"
   },
   "source": [
    "**TODO 15**: Like both previous sections, you are required to pass a threshold of **85%** for this part. Copy the plots and values onto the report and answer questions accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5c5P8X3ShaDn"
   },
   "source": [
    "If you are doing this project individually, you have completed all the compulsory portion of the project code.\n",
    "\n",
    "Please review the rubric before proceeding to extra credits. Note that extra-credits require more effort per grade point than regular credits, so please do not worry if you cannot finish them. That being said, extra-credits are designed to enchance the learning on the topic, and you might want to review it.\n",
    "\n",
    "**Note:** EC1 is compulsory for students doing this project in pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "doyCYfXOhaDn"
   },
   "source": [
    "## Extra Credit 1 Ablation Studies for SimpleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvTpi2cPhaDo"
   },
   "source": [
    "After you have implemented the SimpleNet and play with the parameters, you have a better understanding of Convolutional Neural Network. Now let's do some ablation studies about the simple net. How those parameters will influence the performance of your simple network?\n",
    "\n",
    "**Hint:** you can think about kernel size, number of convolutional layers, fully connected layers, normalization layers, the input image size.\n",
    "\n",
    "You need to perform atleast 3 ablation studies and analyse the accuracy as well as the training/inference time. Please keep track of your experiments and the results as you are required to add them to the report. The experiments should demonstrate an effect on accuracy/timing and you need to provide your reasoning behind it. Your thought process and experiment design is more important than getting _correct observations_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qs8wn_johaDp"
   },
   "source": [
    "**TODO EC1** Please fill the ```optimizer_config``` in the next cell with well-tuned parameter same with the value for your simple net. Change the model structure from ```SimpleNet``` in ```simple_net_ablation.py```. you will need to fill the ```__init__``` and ```forward``` in that file like what you did previously but with different hyperparameters.\n",
    "\n",
    "Repeat this TODO multiple times to perform 3 studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Qb7yOuQhaDq"
   },
   "outputs": [],
   "source": [
    "inp_size = (64,64)\n",
    "optimizer_config = {\n",
    "  \"optimizer_type\": \"AdamW\",\n",
    "  \"lr\": 1e-4,\n",
    "  \"weight_decay\": 1e-3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbLebDerhaDr"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def eval_time(model: torch.nn.Module, input_tensor: torch.Tensor):\n",
    "    model.eval()\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        model(input_tensor)\n",
    "    end = time.time()\n",
    "    return (end-start)/100\n",
    "\n",
    "def print_time(model1: torch.nn.Module, model2: torch.nn.Module, input_tensor: torch.Tensor):\n",
    "    print(\"The time taken for original simple net is {:.9f}\".format(eval_time(model1, input_tensor)))\n",
    "    print(\"The time taken for ablated simple net is {:.9f}\".format(eval_time(model2, input_tensor)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EJKhnodLhaDv",
    "outputId": "8c465fb3-7c02-4917-bf50-e3124d3605c5"
   },
   "outputs": [],
   "source": [
    "simple_model = SimpleNet()\n",
    "optimizer = get_optimizer(simple_model, optimizer_config)\n",
    "\n",
    "trainer = Trainer(data_dir=data_base_path, \n",
    "                  model = simple_model,\n",
    "                  optimizer = optimizer,\n",
    "                  model_dir = os.path.join(model_base_path, 'simple_net'),\n",
    "                  train_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = True,\n",
    "                  cuda = is_cuda\n",
    "                 )\n",
    "_, accuracy = trainer.evaluate()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAdiwxhZhaDx"
   },
   "outputs": [],
   "source": [
    "from proj2_code.simple_net_ablation import SimpleNetAblation\n",
    "\n",
    "simple_model_ablation = SimpleNetAblation()\n",
    "optimizer_ablation = get_optimizer(simple_model_ablation, optimizer_config)\n",
    "\n",
    "trainer_ablation = Trainer(data_dir=data_base_path, \n",
    "                  model = simple_model_ablation,\n",
    "                  optimizer = optimizer_ablation,\n",
    "                  model_dir = os.path.join(model_base_path, 'simple_net_ablation'),\n",
    "                  train_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = False,\n",
    "                  cuda = is_cuda\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "FsOKhLPMhaD0",
    "outputId": "c6a76ff2-d71b-4043-b06a-1c1cd557f6dd"
   },
   "outputs": [],
   "source": [
    "ablation_train_start = time.time()\n",
    "trainer_ablation.train(num_epochs=30)\n",
    "ablation_train_end = time.time()\n",
    "print(\"The training time taken for tuned simple net is {:.9f}\".format(ablation_train_end-ablation_train_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dvtfXEC-n92c",
    "outputId": "f3a0fad6-1bcf-492d-f727-27e463f42669"
   },
   "outputs": [],
   "source": [
    "_, accuracy_ablation = trainer_ablation.evaluate()\n",
    "print(accuracy_ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "A3oO1AnfhaD1",
    "outputId": "3b10dc7c-3069-4567-8262-887c7dfc700c"
   },
   "outputs": [],
   "source": [
    "trainer_ablation.plot_loss_history()\n",
    "trainer_ablation.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "u78YGxgEhaD3",
    "outputId": "2c44cb54-ffa1-44a0-a3be-463f98a68ad1"
   },
   "outputs": [],
   "source": [
    "sample_input, _ = next(iter(image_loader))\n",
    "sample_input = sample_input.unsqueeze(0)\n",
    "\n",
    "if is_cuda:\n",
    "    sample_input = sample_input.to('cuda')\n",
    "\n",
    "print_time(simple_model, simple_model_ablation, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJNZaFSqhaD5"
   },
   "source": [
    "## Extra Credit 2: Model Space/Compute improvement\n",
    "\n",
    "We have created the AlexNet model which performs really well. But can we deploy on a robot which does not have access to powerful GPUs. What if we want to make the model simpler and faster for inference. One option will be to use SimpleNet or a variant of it. But that has very low accuracy compared to AlexNet.\n",
    "\n",
    "Can we utilize the AlexNet model which we have learnt and improve the memory/compute usage? This is an active research area with [several possible options](https://arxiv.org/pdf/1710.09282.pdf).\n",
    "\n",
    "In this part, we will try quantizing our filter weights from 32-bit floating point to 8-bit integer. As you can guess, all the weights in the layers (in convolution and fully connected layers) will have a 75% reduction from this simple switch.\n",
    "\n",
    "What about compute time? The first benefit is directly from lower memory foot-print. We can transfer more weights in the fixed memory bandwith and the cache can hold more weights too. Some CPU architectures might have INT8 computation units which can offer more speedup.\n",
    "\n",
    "We might lose some accuracy when we sacrifice precision. Doing the fp32->int8 conversion directly is a bad choice. \n",
    "Suppose an activation is in a small range of $[0.1, 0.2]$. We cannot just round the weights as the activation might be the same for all the inputs. Hence we need to quantize based on the statistics of the activations.\n",
    "\n",
    "This is a very brief introduction, and we expect you to read material online to complete this section.\n",
    "[Pytorch's Introduction to Quantization](https://pytorch.org/blog/introduction-to-quantization-on-pytorch/) is a good starting point. We used the post-training static quantization scheme and got good performance. You are free to use any quantization scheme as long as it falls within one of the buckes of the rubric.\n",
    "\n",
    "**TODO EC2.1**: Write the ```forward``` function in ```my_alexnet_quantized.py```. Do remember that the input and the output of the function will not be quantized and you need to pass them through a layer for quantization/dequantization.\n",
    "\n",
    "\n",
    "**TODO EC2.2**: Write the ```quantize_model``` function in ```quantization.py```.\n",
    "\n",
    "**Grading**: There are no unit tests for this portion. You will be required to write your idea, paste code snippets, and results in the report. The rubric for this section is a bit complicated and it is recommended to review it before proceeding further.\n",
    "\n",
    "Please note that not all possible buckets may be possible to achieve using simple post-training static quantization scheme. You can obtain a decent performance here and come back later if you are inclined. Make sure you understand what you are doing as 2 points will be alloted for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3W2xS4ShaD5"
   },
   "outputs": [],
   "source": [
    "from proj2_code.quantization import quantize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6YBIj4jhaD7"
   },
   "outputs": [],
   "source": [
    "inp_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLY3-92zhaD8"
   },
   "outputs": [],
   "source": [
    "original_model = MyAlexNet().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7RCEz4vYhaD_"
   },
   "outputs": [],
   "source": [
    "alexnet_trainer = Trainer(data_dir=data_base_path, \n",
    "                  model = original_model,\n",
    "                  optimizer = get_optimizer(original_model, optimizer_config),\n",
    "                  model_dir = os.path.join(model_base_path, 'alexnet'),\n",
    "                  train_data_transforms = get_data_augmentation_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = True,\n",
    "                  cuda = False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wb66xBschaEB"
   },
   "outputs": [],
   "source": [
    "image_loader = ImageLoader(data_base_path, \n",
    "                           split='train', \n",
    "                           transform=get_fundamental_transforms(inp_size, dataset_mean, dataset_std)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIgwwiLshaED"
   },
   "outputs": [],
   "source": [
    "quantized_alexnet = quantize_model(original_model, image_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7ELeeAXhaEF"
   },
   "outputs": [],
   "source": [
    "quantized_alexnet_trainer = Trainer(data_dir=data_base_path, \n",
    "                  model = quantized_alexnet,\n",
    "                  optimizer = get_optimizer(original_model, optimizer_config),\n",
    "                  model_dir = os.path.join(model_base_path, 'quantized_alexnet'),\n",
    "                  train_data_transforms = get_data_augmentation_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  test_data_transforms = get_fundamental_transforms(inp_size, dataset_mean, dataset_std),\n",
    "                  batch_size = 32,\n",
    "                  load_from_disk = False,\n",
    "                  cuda = False\n",
    "                 )\n",
    "\n",
    "quantized_alexnet_trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTRFv4D3haEH"
   },
   "source": [
    "### Size comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssNmgOCNhaEH"
   },
   "outputs": [],
   "source": [
    "quantized_alexnet_size = os.path.getsize(os.path.join(model_base_path, 'quantized_alexnet', 'checkpoint.pt'))/1e6\n",
    "alexnet_size = os.path.getsize(os.path.join(model_base_path, 'alexnet', 'checkpoint.pt'))/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "rn_vbAMohaEJ",
    "outputId": "11514b3a-6c2b-4d6b-83e5-18ea2aabb9cc"
   },
   "outputs": [],
   "source": [
    "print('Original Alexnet Size: {:.2f}'.format(alexnet_size))\n",
    "print('Quantized Alexnet Size: {:.2f}'.format(quantized_alexnet_size))\n",
    "print('Percentage reduction: {:.2f}%'.format(100-100*quantized_alexnet_size/alexnet_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SY7N9paphaEM"
   },
   "source": [
    "Now let's have your model predict on some examples and see how well it performs qualitatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3lo7-Hddnlou"
   },
   "source": [
    "### Speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u83cw0MxhaEP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_forward_pass(model: torch.nn.Module, input_tensor: torch.tensor) -> float:\n",
    "    model.eval()\n",
    "    start = time.time()\n",
    "    for _ in range(300):\n",
    "        model(input_tensor)\n",
    "    end = time.time()\n",
    "    \n",
    "    return (end-start)/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIY2v2s5haEY"
   },
   "outputs": [],
   "source": [
    "sample_input, _ = next(iter(image_loader))\n",
    "sample_input = sample_input.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4pAK68ohaEb"
   },
   "outputs": [],
   "source": [
    "quantized_alexnet_time = time_forward_pass(quantized_alexnet, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ldb6amFchaEc"
   },
   "outputs": [],
   "source": [
    "alexnet_time = time_forward_pass(original_model, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "PJUdiCrehaEd",
    "outputId": "13a6d5a5-416b-431d-8297-cb03bdcbadca"
   },
   "outputs": [],
   "source": [
    "print('Original Alexnet Time: {:.2f}'.format(alexnet_time))\n",
    "print('Quantized Alexnet Time: {:.2f}'.format(quantized_alexnet_time))\n",
    "print('Percentage reduction: {:.2f}%'.format(100-100*quantized_alexnet_time/alexnet_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teAdeSYmhaEf"
   },
   "outputs": [],
   "source": [
    "_, alexnet_accuracy = alexnet_trainer.evaluate()\n",
    "_, quantized_alexnet_accuracy = quantized_alexnet_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "WKN3q0vMhaEi",
    "outputId": "9f20ccaf-39bf-45df-bc38-1c4beef94876"
   },
   "outputs": [],
   "source": [
    "print('Original Alexnet Accuracy: {:.2f}'.format(alexnet_accuracy))\n",
    "print('Quantized Alexnet Accuracy: {:.2f}'.format(quantized_alexnet_accuracy))\n",
    "print('Percentage reduction: {:.2f}%'.format(100-100*quantized_alexnet_accuracy/alexnet_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNyC74luhaEu"
   },
   "source": [
    "### Extra Credit 3 Classification Performance Analysis\n",
    "\n",
    "In this part, you will need to analyze the performance of your models by evaluating your model's predictions. To do that, you could use the metrics scores, such as precision, recall, F1 score, confusion matrix, etc. Since we care more about your reasoning and reflection here, you can directly use functions from `sklear.metrics`. You can find the list of available metrics and what each one is assessing [here](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics).\n",
    "\n",
    "**TODO EC3.1:** implement the function `evaluate` in `analyze.py`. Then use metrics scores returned by this function to evaluate the quality of predictions on the **test** split for `SimpleNet`, `SimpleNetDropout`, and `MyAlexNet`, anaylze the performance of the models, and put your analysis in the report.\n",
    "\n",
    "Here, we ask you to compute the confusion matrix as one of the metrics. You don't have to compute it manually, instead, you could use the function from `sklearn.metrics` or `PyCM`. You can refer to the documentation of [the sklearn function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html), or if you prefer `PyCM` package, you can refer to its [full documentation](https://www.pycm.ir/doc/index.html#Usage) or [an example of usage](https://www.pycm.ir/doc/Example1.html). You could also learn more about the confusion matrix itself in its [wiki](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "\n",
    "Besides the confusion matrix, you also need to use at least 1 and at most 3 additional metrics of your own choise. You don't need to compute any metrics manually, instead, you could just call the functions from `sklearn.metrics`. Since accuracy is already reported during training, accuracy will **NOT** count in this part, but you can use it in your analysis. \n",
    "\n",
    "You need to do two things in your `evaluate` function.\n",
    "1. compute the confusion matrix and return it\n",
    "2. compute 1 to 3 additional metrics scores and return them.\n",
    "\n",
    "Note that your code is not the main issue here as you are free to use third party modules. Please make sure you understand what the results mean and you can reflect on the observations.\n",
    "\n",
    "**TODO EC3.2:** please answer the following questions in your report.\n",
    "* What are your confusion matrices for each model? What information do they give you and what do you think about it?\n",
    "* What additional metrics are you using? What are the scores and how are they evaluating the model's performance? What do you think could possibly improve the performance?\n",
    "\n",
    "**Grading**: There are no unit tests for this portion. You will be required to write your idea and results in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "hKdRhhbdqfsa",
    "outputId": "b03ed603-81ed-40cc-b37f-cec537ce6da4"
   },
   "outputs": [],
   "source": [
    "# will need to run this on Colab as we are not using conda environment\n",
    "# !pip install pycm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzG2qnBIhaEv"
   },
   "outputs": [],
   "source": [
    "from proj2_code.analyze import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_9B-aRehaEw"
   },
   "outputs": [],
   "source": [
    "# get image loader\n",
    "inp_size = (64, 64)\n",
    "image_loader = ImageLoader(data_base_path,\n",
    "                           split='test',\n",
    "                           transform=get_fundamental_transforms(inp_size, dataset_mean, dataset_std)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58JuvNDEhaEx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1500])\n",
      "torch.Size([1500])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3ed2d29ed683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmetrics_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision_score\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmetrics_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/computervision/proj2_part2_release/proj2_code/analyze.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, image_loader, is_cuda, metrics_fn, metrics_args, model_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0;31m# instead of predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj2/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj2/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj2/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1434\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj2/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1264\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "### Evaluate SimpleNet ###\n",
    "# Load the model from saved checkpoints\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "simple_net = SimpleNet()\n",
    "model_dir = os.path.join(model_base_path, 'simple_net', 'checkpoint.pt')\n",
    "\n",
    "# evaluate the model\n",
    "metrics_list = [f1_score,precision_score ]\n",
    "metrics_args = [{}, {weighted}]\n",
    "cm, scores = evaluate(simple_net, image_loader, is_cuda, metrics_list, metrics_args, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clQtnWKyhaEz"
   },
   "outputs": [],
   "source": [
    "### Student TODO: you can print the confusion matrix and evaluation scores here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aI9aJq5xhaE0"
   },
   "outputs": [],
   "source": [
    "### Evaluate SimpleNetDropout ###\n",
    "\n",
    "# Load the model from saved checkpoints\n",
    "simple_net_dropout = SimpleNetDropout()\n",
    "model_dir = os.path.join(model_base_path, 'simple_net_dropout', 'checkpoint.pt')\n",
    "\n",
    "metrics_list = []\n",
    "metrics_args = []\n",
    "cm, scores = evaluate(simple_net_dropout, image_loader, is_cuda, metrics_list, metrics_args, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjrHV-1UhaE2"
   },
   "outputs": [],
   "source": [
    "### Student TODO: you can print the confusion matrix and evaluation scores here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6-IFlrUrUtz"
   },
   "outputs": [],
   "source": [
    "# get image loader\n",
    "inp_size = (224, 224)\n",
    "image_loader = ImageLoader(data_base_path,\n",
    "                           split='test',\n",
    "                           transform=get_fundamental_transforms(inp_size, dataset_mean, dataset_std)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxEPdTQChaE4"
   },
   "outputs": [],
   "source": [
    "### Evaluate MyAlexNet ###\n",
    "\n",
    "# Load the model from saved checkpoints\n",
    "my_alexnet = MyAlexNet()\n",
    "model_dir = os.path.join(model_base_path, 'alexnet', 'checkpoint.pt')\n",
    "\n",
    "metrics_list = []\n",
    "metrics_args = []\n",
    "cm, scores = evaluate(my_alexnet, image_loader, is_cuda, metrics_list, metrics_args, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jY8-3KzthaE5"
   },
   "outputs": [],
   "source": [
    "### Student TODO: you can print the confusion matrix and evaluation scores here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZaopDcToTdnj"
   },
   "source": [
    "## Code testing\n",
    "We have provided a set of tests for you to evaluate your implementation. We have included tests inside ```proj2.ipynb``` so you can check your progress as you implement each section. At the end, you should call the tests from the terminal using the command ```pytest proj2_code/proj2_unit_tests/```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIfkkgSahaE8"
   },
   "source": [
    "## Submission\n",
    "\n",
    "This is very important as you will lose 5 points for every time you do not follow the instructions.\n",
    "\n",
    "Do install any additional packages inside the conda environment. The TAs will use the same environment as defined in the config files we provide you, so anything that's not in there by default will probably cause your code to break during grading. Do use absolute paths in your code or your code will break. Use relative paths like the starter code already does. Failure to follow any of these instructions will lead to point deductions. Create the zip file using ```python zip_submission.py --gt_username <your_gt_username>``` (it will zip up the appropriate directories/files for you!) and hand it through Gradescope. Remember to submit your report as a PDF to Gradescope as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwzSFdI-haE8"
   },
   "source": [
    "## Rubric\n",
    "We have covered 35 credits in part 1 code. The overall rubric division for this part is:\n",
    "\n",
    "| Submission Type | Credit Type | Individual | Partner |\n",
    "| --------------- | ----------- | ---------- | ------- |\n",
    "| Code            | Mandatory   | 25         | 20      |\n",
    "| Report          | Mandatory   | 40         | 40      |\n",
    "| Report          | EC1         | 4          | 4       |\n",
    "| Report          | EC2         | 9          | 9       |\n",
    "| Report          | EC3         | 4          | 4       |\n",
    "| Total           |             | 82         | 77      |\n",
    "\n",
    "\n",
    "However, the max score for the this part is **capped at 77** for both individual and partner submissions. Hence individual submissions need not do all ECs for maximum possible credits.\n",
    "\n",
    "\n",
    "\n",
    "| Test name | Individual Scores | Partner Scores |\n",
    "| --------- | ----------------- | -------------- |\n",
    "| `test_simple_net_dropout` | 12 | 10 |\n",
    "|`test_my_alexnet` | 13 | 10 |\n",
    "\n",
    "**Rubric for EC2:**\n",
    "- +2 points for describing the strategy and explaining the main ideas in the report.\n",
    "\n",
    "Your results will fall in only one of these buckets. All the conditions in the bucket have to be satisfied to gain the points\n",
    "- +1 points for achieving >70% reduction in size, >20% reduction in speed, <10% reduction in accuracy\n",
    "- +2 points for achieving >70% reduction in size, >20% reduction in speed, <3% reduction in accuracy\n",
    "- +4 points for achieving >70% reduction in size, >20% reduction in speed, <0.75% reduction in accuracy\n",
    "- +4 points for achieving >70% reduction in size, >70% reduction in speed, <2% reduction in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lMUaxM3GhaE8"
   },
   "source": [
    "## Credit\n",
    "\n",
    "Assignment developed by Ayush Baid, Haoxin Ma, Jing Wu and Frank Dellaert, based on a the original assigment by Ayush Baid, Cusuh Ham, Jonathan Balloch, Shenhao Jiang, Frank Dellaert, and James Hays."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "proj6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "069982490a6f40c99dd18422032d2c88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92f6efa8b5fd49e69bdada865cbc3fab",
      "max": 244418560,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6ecbfe7ee7b4d4da398c5ee56badae9",
      "value": 244418560
     }
    },
    "0b81f9c1f6bc454a87fe4778bf952649": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_069982490a6f40c99dd18422032d2c88",
       "IPY_MODEL_5cb5fa8ce08046aab383a70a67501a4b"
      ],
      "layout": "IPY_MODEL_fd2dd89a02c845749277122b6b6ff950"
     }
    },
    "5cb5fa8ce08046aab383a70a67501a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88ea6259ff60465884b7d21ee6b48479",
      "placeholder": "​",
      "style": "IPY_MODEL_c6638c5846de4196a0a8238b10db6cdd",
      "value": " 233M/233M [01:46&lt;00:00, 2.30MB/s]"
     }
    },
    "88ea6259ff60465884b7d21ee6b48479": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92f6efa8b5fd49e69bdada865cbc3fab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6638c5846de4196a0a8238b10db6cdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6ecbfe7ee7b4d4da398c5ee56badae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fd2dd89a02c845749277122b6b6ff950": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
